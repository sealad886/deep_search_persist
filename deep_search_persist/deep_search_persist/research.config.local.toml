[LocalAI]
ollama_base_url = "${OLLAMA_BASE_URL}"
default_model_ctx = 256000
reason_model_ctx = -1

[API]
openai_compat_api_key = "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"
jina_api_key = "jina_55069093954b401bbcb45431c1890094ekvmN8ZUN_cI2ohruBrxJIt_9zO-"
openai_url = "https://openrouter.ai/api/v1/chat/completions"
jina_base_url = "https://r.jina.ai/"
searxng_url = "http://host.docker.internal:4000/search"

[Settings]
use_jina = false
use_ollama = true
with_planning = true
default_model = "gemma3:4b"
reason_model = "qwen3:14b"

[Concurrency] # for browser
concurrent_limit = 3
cool_down = 10.0
chrome_port = 9222
chrome_host_ip = "http://host.docker.internal"
use_embed_browser = true

[Parsing]
temp_pdf_dir = "/app/temp_pdf_data"
browse_lite = 0
pdf_max_pages = 30
pdf_max_filesize = 20971520
timeout_pdf = 120
max_html_length = 5120
max_eval_time = 180
verbose_web_parse_detail = true

[Ratelimits] # for AI endpoints
request_per_minute = 12
operation_wait_time = 10
fallback_model = "llama3.2:3b-instruct-q8_0"
